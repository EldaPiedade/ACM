# Machine-Learning-ACM-Tutorials
ACM Data Science WorkShops

Workshop 1 
* Delivered in Person to 30 Students
* Notebook is not detailed
* Link https://github.com/EldaPiedade/Machine-Learning-ACM-Tutorials/blob/master/Workshop%201/Work_Books/ACM_DataScience_Workshop1_EldaPiedade_Feb1920.ipynb
* Authers: Elda & Ethan

During the first workshop we achieved the following:

* Explored the data and decided to use the columns that contain numerical data only.
* Identified how many null (NaN values were in each column of data).
* Deleted all rows (from numerical columns) that contained null values.
* Create a basic Random Forest model and Understood its mechanism.
* Learned how to split the data into train and validation sets to test the performance of the model.
* Finally we created a Kaggle account and submitted our results here -->https://www.kaggle.com/c/house-prices-advanced-regression-techniques

Workshop 2
* Posted to Slack channel, open to ACM Members
* Notebook is meant for an audience that attended the first workshop
* Link https://github.com/EldaPiedade/Machine-Learning-ACM-Tutorials/blob/master/Workshop%202/ACM_DataScience_Workshop2.ipynb
* Auther: Elda Piedade

For this workshop we will extend the same concepts learned and go a little further:

* We will now use numerical and categorical data to predict homes prices in Iowa. Because models only understand numerical data, we will convert the categorical into numerical data in different ways.
* Instead of deleting the rows of data containing null values and losing information, we will learn different ways to estimate possible values to substitute for the null values.
* We will now create a new model called XBboost. Resources to understand how it works will be available.
* Instead of splitting the data once to validate our model, we will learn how to cross-validate to obtain a better overview of the model's performance.
